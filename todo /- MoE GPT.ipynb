{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WiMo--TVOhjC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT dataset\n",
        "This is a collection of Questions and answers to gpt3.5 and 4. <br>\n",
        "Each question and answer is concatenated and truncated at the 500th character to have something bigger than tinyshakespeare to train on. <br> \n",
        "You shouldn't do this in a production enviroment. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4i9JBOGeO-DG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([96004, 1088])\n",
            "2aéKÃf“oqěfo50лл0mK“zo40“qfâqaooLIHK“zoqěfonсссoxI"
          ]
        }
      ],
      "source": [
        "dataset = torch.load(\"datasets/gpt_dataset.pt\")[20:]\n",
        "valset = torch.load(\"datasets/gpt_dataset.pt\")[:20]\n",
        "ctoi = pickle.load(open(\"datasets/gpt_ctoi.pkl\", \"rb\"))\n",
        "itoc = pickle.load(open(\"datasets/gpt_itoc.pkl\", \"rb\"))\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "sequence_length = 64\n",
        "vocab_size = torch.max(dataset) + 1\n",
        "X = dataset.to(device)\n",
        "print(X.shape)\n",
        "\n",
        "for c in dataset[0][:50]:\n",
        "    print(itoc[c.item()], end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(140, dtype=torch.uint8)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFgYBnvsN7gL",
        "outputId": "ce8752d0-7c63-4d89-fa1f-d445c57425a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Millions of parameters:  14.43\n"
          ]
        }
      ],
      "source": [
        "act = F.gelu\n",
        "HIDDEN_SIZE = 512\n",
        "\n",
        "class FullyConnected(nn.Module):\n",
        "    def __init__(self, in_size, out_size, hidden_size=HIDDEN_SIZE):\n",
        "        super(FullyConnected, self).__init__()\n",
        "        self.LayerNorm = nn.LayerNorm(in_size)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.LayerNorm(x)\n",
        "        x = act(self.fc1(x))\n",
        "        x = act(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "class MoE(nn.Module):\n",
        "    def __init__(self, in_size, out_size, hidden_size=HIDDEN_SIZE, depth=4, n_experts=5):\n",
        "        super(MoE, self).__init__()\n",
        "        self.LayerNorm = nn.LayerNorm(in_size)\n",
        "\n",
        "        self.fcin = nn.Linear(in_size, hidden_size)\n",
        "        self.experts = nn.ModuleList([nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(n_experts)]) for _ in range(depth)])\n",
        "        self.fcout = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, x, chosen_expert=None):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.LayerNorm(x)\n",
        "        x = act(self.fcin(x))\n",
        "        choice = torch.multinomial(torch.softmax(x[:, :4], 1), 1)[:, 0]\n",
        "        if chosen_expert is None: # It might be that i goth this the other way around, doesnt matter if depth and n_experts are the same\n",
        "            for i in range(len(self.experts)):\n",
        "                for expert in self.experts[i]:\n",
        "                    x[choice == i] += act(expert(x[choice == i]))\n",
        "        else:\n",
        "            for i in range(len(self.experts)):\n",
        "                expert = self.experts[i][chosen_expert]\n",
        "                x[choice == i] += act(expert(x[choice == i]))\n",
        "\n",
        "        x = self.fcout(x)\n",
        "        return x\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Attention, self).__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.keys = nn.Linear(config.emb_size, config.head_size)\n",
        "        self.queries = nn.Linear(config.emb_size, config.head_size)\n",
        "        self.values = nn.Linear(config.emb_size, config.head_size)\n",
        "        self.norm = nn.LayerNorm(sequence_length*config.emb_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x.view(x.shape[0], -1)).view(x.shape[0], sequence_length, self.config.emb_size)\n",
        "\n",
        "        k = self.keys(x)     # [Batch_size, time, head_size]\n",
        "        q = self.queries(x)  # [Batch_size, time, head_size]\n",
        "        v = self.values(x)   # [Batch_size, time, head_size]\n",
        "\n",
        "        similarity = k @ q.transpose(-2, -1)/(self.config.head_size**0.5)\n",
        "        similarity = torch.tril(similarity)  # [Batch_size, time, time]\n",
        "        similarity[similarity == 0] = float(\"-inf\")\n",
        "        similarity = torch.softmax(similarity, dim = 1)\n",
        "        attention = similarity @ v    # [Batch_size, time, head_size]\n",
        "        return attention\n",
        "\n",
        "class GPTconfig():\n",
        "    pass\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.att = nn.ModuleList([Attention(config) for _ in range(config.n_heads)])\n",
        "        self.MoE = MoE(in_size=sequence_length*config.head_size*config.n_heads, out_size=sequence_length*config.emb_size, n_experts=config.n_experts)\n",
        "\n",
        "\n",
        "    def forward(self, x, chosen_expert=None):  # inputs: [Batch_size, time, vocab_size]\n",
        "        batch_size = x.shape[0]\n",
        "        \n",
        "        x = torch.cat([att(x) for att in self.att], dim=1)\n",
        "        x = x.view(batch_size, self.config.head_size*self.config.n_heads*sequence_length)\n",
        "        x = self.MoE(x, chosen_expert).view(x.shape[0], sequence_length, self.config.emb_size)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_experts=5):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        config = GPTconfig()\n",
        "        config.vocab_size = X.max() + 1\n",
        "        config.head_size = 20\n",
        "        config.emb_size = 8\n",
        "        config.n_heads = 5\n",
        "        config.n_blocks = 3\n",
        "        config.n_experts = n_experts\n",
        "        self.config = config\n",
        "\n",
        "        self.pemb = nn.Embedding(sequence_length, config.emb_size)\n",
        "        self.wemb = nn.Embedding(config.vocab_size, config.emb_size)\n",
        "        self.blocks = nn.ModuleList([Block(config) for i in range(config.n_blocks)])\n",
        "        self.lout = FullyConnected(in_size=sequence_length*config.emb_size, out_size=config.vocab_size)\n",
        "\n",
        "    def forward(self, x, chosen_expert=None):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # embeddings\n",
        "        pemb = self.pemb(torch.arange(sequence_length).to(device)).view(1, sequence_length, self.config.emb_size) # [time, emb_size]\n",
        "        wemb = self.wemb(x)        # [Batch_size, time, emb_size]\n",
        "\n",
        "        x = wemb + pemb\n",
        "        \n",
        "        for block in self.blocks:\n",
        "            x = x + block(x, chosen_expert=chosen_expert)\n",
        "        self.std = x.std()\n",
        "        x = self.lout(x)\n",
        "        return x\n",
        "\n",
        "Net = Model(n_experts=1).to(device)\n",
        "lossi = []\n",
        "vlossi = []\n",
        "print(\"Millions of parameters: \", round(sum(p.numel() for p in Net.parameters() if p.requires_grad)/1000000, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9l7mQjGXvi_",
        "outputId": "f087bad1-586c-4f1a-b6db-996f78ff5c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percent of dataset:  0.020832465313945253\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 250/250 [06:23<00:00,  1.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 6min 23s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "epochs = 250\n",
        "batch_size = 8\n",
        "print(\"Percent of dataset: \", epochs*batch_size / X.shape[0])\n",
        "\n",
        "optimizer = torch.optim.Adam(Net.parameters(), lr=3e-4)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    indexes = torch.randint(len(dataset), (batch_size, ))\n",
        "    indexesb = torch.arange(sequence_length+1).repeat(1024).view(1024, sequence_length+1) + torch.arange(1024).view(1024, 1)\n",
        "\n",
        "    batch = X[indexes][:, indexesb[:, :-1]].view(-1, sequence_length)\n",
        "    pred = Net(batch.long().to(device))\n",
        "    loss = F.cross_entropy(pred, X[indexes][:, indexesb[:, -1]].view(-1).to(device))\n",
        "    lossi.append(loss.item())\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if epoch % 10 == 0:\n",
        "            indexes = torch.randint(len(valset), (batch_size, ))\n",
        "            indexesb = torch.arange(sequence_length+1).repeat(1024).view(1024, sequence_length+1) + torch.arange(1024).view(1024, 1)\n",
        "\n",
        "            batch = valset[indexes][:, indexesb[:, :-1]].view(-1, sequence_length)\n",
        "            pred = Net(batch.long().to(device))\n",
        "            loss = F.cross_entropy(pred, valset[indexes][:, indexesb[:, -1]].view(-1).to(device))\n",
        "            vlossi.append(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Net = Model(n_experts=1).to(device)\n",
        "lossi = []\n",
        "vlossi = []\n",
        "print(\"Millions of parameters: \", round(sum(p.numel() for p in Net.parameters() if p.requires_grad)/1000000, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "epochs = 250\n",
        "batch_size = 8\n",
        "print(\"Percent of dataset: \", epochs*batch_size / X.shape[0])\n",
        "\n",
        "optimizer = torch.optim.Adam(Net.parameters(), lr=3e-4)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    indexes = torch.randint(len(dataset), (batch_size, ))\n",
        "    indexesb = torch.arange(sequence_length+1).repeat(1024).view(1024, sequence_length+1) + torch.arange(1024).view(1024, 1)\n",
        "\n",
        "    batch = X[indexes][:, indexesb[:, :-1]].view(-1, sequence_length)\n",
        "    pred = Net(batch.long().to(device))\n",
        "    loss = F.cross_entropy(pred, X[indexes][:, indexesb[:, -1]].view(-1).to(device))\n",
        "    lossi.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if epoch % 10 == 0:\n",
        "            indexes = torch.randint(len(valset), (batch_size, ))\n",
        "            indexesb = torch.arange(sequence_length+1).repeat(1024).view(1024, sequence_length+1) + torch.arange(1024).view(1024, 1)\n",
        "\n",
        "            batch = valset[indexes][:, indexesb[:, :-1]].view(-1, sequence_length)\n",
        "            pred = Net(batch.long().to(device))\n",
        "            loss = F.cross_entropy(pred, valset[indexes][:, indexesb[:, -1]].view(-1).to(device))\n",
        "            vlossi.append(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "-NyBckuBZG_6",
        "outputId": "0772d68d-6e63-4867-c0c8-38c23677a62c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x15f8416acd0>]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(torch.tensor(lossi[::]).view(-1, 1).mean(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percent of dataset:  0.04165625260351579\n",
            "Expert:  0  Loss:  2.75364089012146\n",
            "Expert:  1  Loss:  2.857095718383789\n",
            "Expert:  2  Loss:  2.9408631324768066\n",
            "Expert:  3  Loss:  2.9137661457061768\n",
            "Expert:  4  Loss:  2.9295036792755127\n",
            "Expert:  None  Loss:  1.5102663040161133\n",
            "Wall time: 701 ms\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "\n",
        "epochs = 1000\n",
        "batch_size = 4\n",
        "print(\"Percent of dataset: \", epochs*batch_size / X.shape[0])\n",
        "\n",
        "with torch.no_grad():\n",
        "    for expert in [i for i in range(5)] + [None]:\n",
        "        indexes = torch.randint(len(dataset)-sequence_length-2, (batch_size, ))\n",
        "        indexesb = torch.arange(sequence_length+1).repeat(1024).view(1024, sequence_length+1) + torch.arange(1024).view(1024, 1)\n",
        "\n",
        "        batch = X[indexes][:, indexesb[:, :-1]].view(-1, sequence_length)\n",
        "        pred = Net(batch.long().to(device), chosen_expert=expert)\n",
        "        loss = F.cross_entropy(pred, X[indexes][:, indexesb[:, -1]].view(-1).to(device))\n",
        "    \n",
        "        print(\"Expert: \", expert, \" Loss: \", loss.item())\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import random\n",
        "pickle.dump(Net, open(f\"model-1h{random.randint(0, 100000)}.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "Net = pickle.load(open(\"model-1h.pkl\", \"rb\"))\n",
        "ctoi = pickle.load(open(\"ctoi.pkl\", \"rb\"))\n",
        "itoc = pickle.load(open(\"itoc.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNCIn4KHmITi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fo0\"BToBdнZToBd¤Zс@ся@To’сo2Iff“oблK\"fуo_“YлfqB–o8DлDqK0“o–fÃf“qHYo–IзлK4Dqfoqěfoзfqmff“ToD“oD“–mfHrüroб0\"foqěD“o|у\"0“zo50HoqěK–oDHqK–qToK“–qD“4foзI–"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7776/2627448320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mctoi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mitoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7776/4224971515.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, chosen_expert)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchosen_expert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchosen_expert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\lucam\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7776/4224971515.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, chosen_expert)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0matt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMoE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchosen_expert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memb_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\lucam\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7776/4224971515.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, chosen_expert)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mexpert\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchoice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchoice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "prompt = \" \"*60 + \"The meaning of life is... \\nKI\"\n",
        "device = torch.device(\"cuda:0\")\n",
        "sequence_length = 64\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(300):\n",
        "        X = torch.tensor([ctoi[s] for s in prompt[-sequence_length:]]).long().view(1, -1).to(device)\n",
        "        pred = Net.forward(X)\n",
        "        prompt += itoc[torch.multinomial(F.softmax(pred, dim=1), 1).item()]\n",
        "        print(prompt[-1], end=\"\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
