{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "device = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you\n"
     ]
    }
   ],
   "source": [
    "with open(\"datasets/tinyShakespeare.txt\", \"r\") as f:\n",
    "    load = f.read()\n",
    "print(load[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texttoint = {elm: n for n, elm in enumerate(set(load))}\n",
    "inttotext = {n:elm for n, elm in enumerate(set(load))}\n",
    "dataset = [texttoint[c] for c in load]\n",
    "\n",
    "vocab_size = len(texttoint)\n",
    "sequence_length = 20\n",
    "\n",
    "sequences = torch.tensor([dataset[i:-sequence_length+i-1] for i in range(sequence_length+1)]).T\n",
    "inputs = sequences[2000:, :-1]\n",
    "labels = sequences[2000:, -1]\n",
    "val_inputs = sequences[:2000, :-1]\n",
    "val_labels = sequences[:2000, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Block - Scaled dot product attention\n",
    "\n",
    "A very effective system that can find correlations between tokens is the attention block <br><br>\n",
    "\n",
    "It takes in a series of tokens: input (sequence_length, embedding_size)<br>\n",
    "we call this layer \"attention head\", you can have one head of self attention or many heads with different weights. <br> \n",
    "and computes the dot products with 3 sets of weights, called \"keys\", \"queries\" and \"values\" of size (emb_size, head_size) <br>\n",
    " \n",
    "After this operation you have three tensors of size (sequence_length, head_size) <br>\n",
    "you compute the similarity matrix (sequence_length, sequence_length) by multiplying keys with transposed queries. <br><br>\n",
    "\n",
    "The next step is to tril (transform to lower triangular) and softmax the similarity matrix, and a scaling by sqrt(head_size) <br>\n",
    "(This is why its called scaled dot product attention) <br>\n",
    "Following is a dot product with the values. The output will be (sequence_length, head_size) <br>\n",
    "\n",
    "This block has roughly a complexity of O(sequence_length^2) witch is sub optimal for long sequence lengths, so we use sligthly different attention blocks for that<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.181812763214111\n",
      "1.7210773229599\n",
      "1.6213728189468384\n",
      "1.5663319826126099\n",
      "1.5551037788391113\n",
      "1.5286071300506592\n",
      "1.5103294849395752\n",
      "1.4697332382202148\n",
      "1.4472392797470093\n",
      "1.493862509727478\n"
     ]
    }
   ],
   "source": [
    "class Attention(nn.Module):  # This is the masked attention module\n",
    "    def __init__(self, emb_size=10, head_size=128):\n",
    "        super(Attention, self).__init__()\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.keys = nn.Linear(emb_size, head_size)\n",
    "        self.queries = nn.Linear(emb_size, head_size)\n",
    "        self.values = nn.Linear(emb_size, head_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # attention\n",
    "        k = self.keys(x)\n",
    "        q = self.queries(x)\n",
    "        v = self.values(x)\n",
    "\n",
    "        similarity = k @ q.transpose(-2, -1)/(self.head_size**0.5)\n",
    "        similarity = torch.tril(similarity)\n",
    "        similarity[similarity == 0] = float(\"-inf\")\n",
    "        similarity = torch.softmax(similarity, dim = 1)\n",
    "        \n",
    "        attention = similarity @ v \n",
    "        return attention\n",
    "\n",
    "\n",
    "class FullyConnected(nn.Module):  # This is basically what we had before, the simple MLP without residual connections\n",
    "    def __init__(self, in_size=10, hidden_size=128, out_size=vocab_size, n_layers=2):\n",
    "        super(FullyConnected, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_size*sequence_length, hidden_size)\n",
    "        self.fcx = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(n_layers)])\n",
    "        self.fc2 = nn.Linear(hidden_size, out_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        for fc in self.fcx:\n",
    "            x = F.gelu(fc(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):  # This is the block that we will use in the transformer\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        emb_size = 10\n",
    "        self.head_size = head_size = 128\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_size)\n",
    "        self.att = Attention(emb_size, head_size).to(device)\n",
    "        self.fc = FullyConnected(head_size).to(device)\n",
    "\n",
    "    def forward(self, x):  # inputs: [Batch_size, time, vocab_size]\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        x = self.embeddings(x)\n",
    "        x = self.att(x) \n",
    "        x = x.view(batch_size, sequence_length*self.head_size)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = Block().to(device)\n",
    "\n",
    "epochs = 10000\n",
    "batch_size = 8192\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    "\n",
    "lossi = []\n",
    "vlossi = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    indexes = torch.randint(0, len(inputs), (batch_size,))\n",
    "    \n",
    "    pred = model(inputs[indexes].to(device)) # everything in the forward pass happens in the model class\n",
    "    loss = F.cross_entropy(pred, labels[indexes].to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "    if epoch % (epochs//10) == 0:\n",
    "        print(loss.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(val_inputs.to(device))\n",
    "        loss = F.cross_entropy(pred, val_labels.to(device))\n",
    "        vlossi.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x239a9c6d6d0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi[:]) # 1.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           \n",
      "KING RICHARD II:\n",
      "Then wwence thee,\n",
      "Suburrigny: forge of lamour\n",
      "When answer. Chrisby:\n",
      "I, the mean\n",
      "anch you have sends of Ballow.\n",
      "\n",
      "SAMPSON:\n",
      "What my heavy she gring, so, see\n",
      "Would for laboursess seeds that we wash?\n",
      "\n",
      "PETER:\n",
      "As I be a richmen:\n",
      "Or all himself an one service in torbour wish all theset's gracioe't?\n",
      "Edwar"
     ]
    }
   ],
   "source": [
    "string = \"           \\nKING RICHARD I\"\n",
    "print(string, end=\"\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(300):\n",
    "        X = torch.tensor([texttoint[s] for s in string[-sequence_length:]]).long().view(1, -1).to(device)\n",
    "        pred = model.forward(X)\n",
    "        string += inttotext[torch.multinomial(F.softmax(pred, dim=1), 1).item()]\n",
    "        print(string[-1], end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers \n",
    "\n",
    "Transformers consist of attention blocks in sequence, with residual connections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.312550067901611\n",
      "1.6860811710357666\n",
      "1.562029242515564\n",
      "1.4947874546051025\n",
      "1.460423469543457\n",
      "1.4215669631958008\n",
      "1.3750406503677368\n",
      "1.3662678003311157\n",
      "1.4118024110794067\n",
      "1.3118298053741455\n"
     ]
    }
   ],
   "source": [
    "class Attention(nn.Module):  \n",
    "    def __init__(self, emb_size=10, head_size=128):\n",
    "        super(Attention, self).__init__()\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.keys = nn.Linear(emb_size, head_size)\n",
    "        self.queries = nn.Linear(emb_size, head_size)\n",
    "        self.values = nn.Linear(emb_size, head_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        k = self.keys(x)\n",
    "        q = self.queries(x)\n",
    "        v = self.values(x)\n",
    "\n",
    "        similarity = k @ q.transpose(-2, -1)/(self.head_size**0.5)\n",
    "        similarity = torch.tril(similarity)\n",
    "        similarity[similarity == 0] = float(\"-inf\")\n",
    "        similarity = torch.softmax(similarity, dim = 1)\n",
    "        \n",
    "        attention = similarity @ v \n",
    "        return attention\n",
    "\n",
    "\n",
    "class FullyConnected(nn.Module):  \n",
    "    def __init__(self, in_size=10, hidden_size=128, out_size=sequence_length*10, n_layers=2):\n",
    "        super(FullyConnected, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_size*sequence_length, hidden_size)\n",
    "        self.fcx = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(n_layers)])\n",
    "        self.fc2 = nn.Linear(hidden_size, out_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        for fc in self.fcx:\n",
    "            x = x + F.gelu(fc(x)) # Residual connection not present in the original paper, but it helps with convergence\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module): \n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size = 128\n",
    "\n",
    "        self.att = Attention(emb_size, head_size).to(device)\n",
    "        self.fc = FullyConnected(head_size, emb_size*sequence_length).to(device)\n",
    "\n",
    "    def forward(self, x):  \n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        x = self.att(x) \n",
    "        x = x.view(batch_size, sequence_length*self.head_size)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Everything is the same upto here. Now we will create a transformer class that combines the blocks\n",
    "class Transformer(nn.Module): \n",
    "    def __init__(self, n_blocks=2):\n",
    "        super().__init__()\n",
    "        emb_size = 10\n",
    "\n",
    "        self.embs = nn.Embedding(vocab_size, emb_size) \n",
    "        self.blocks = nn.ModuleList([Block(emb_size) for _ in range(n_blocks)])\n",
    "        self.LinOut = nn.Linear(emb_size*sequence_length, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        x = self.embs(x)\n",
    "        for block in self.blocks:\n",
    "            x = x + block(x).view(-1, x.shape[1], x.shape[2])\n",
    "        x = self.LinOut(x.view(batch_size, -1))\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = Transformer().to(device)\n",
    "\n",
    "epochs = 10000\n",
    "batch_size = 8192\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4) \n",
    "\n",
    "lossi = []\n",
    "vlossi = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    indexes = torch.randint(0, len(inputs), (batch_size,))\n",
    "    \n",
    "    pred = model(inputs[indexes].to(device)) # everything in the forward pass happens in the model class\n",
    "    loss = F.cross_entropy(pred, labels[indexes].to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "    if epoch % (epochs//10) == 0:\n",
    "        print(loss.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(val_inputs.to(device))\n",
    "        loss = F.cross_entropy(pred, val_labels.to(device))\n",
    "        vlossi.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a51843fd30>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi[200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "As you can see we can get really good loss with the transformer, this architecture scales well up to GPT3.5 level performance with enough high quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millions of parameters:  1.29\n",
      "[650, 1280, 128, 1280, 128, 1280, 128, 512000, 200, 40000, 200, 40000, 200, 40000, 200, 1280, 128, 1280, 128, 1280, 128, 512000, 200, 40000, 200, 40000, 200, 40000, 200, 13000, 65]\n"
     ]
    }
   ],
   "source": [
    "print(\"Millions of parameters: \", round(sum(p.numel() for p in model.parameters() if p.requires_grad)/1000000, 2))\n",
    "print([p.numel() for p in model.parameters() if p.requires_grad])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoE\n",
    "The way these models encode information is in their weights, but you dont always need to compute all of the weights to get to the next token, for example if there is an area of weights that mostly encode the names of cities, you dont need them when the next token is the solution of a quadratic equation. <br>\n",
    "So it stands to reason that you could have many sets of weights that the model can choose to use in real time to get more efficient inference. For instance the mistral Mixture of Experts model uses 8 sets of 7B weights, and at any point in time only 13B parameters are used. Thats a 3-4x speedup over a similar model without MoE with marginal impact on performance. GPT-4 is also based on MoE of 16 x 110B models  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
